# Прогнозирование продаж

## Постановка задачи
**Задача:** Прогнозирование недельных продаж для розничной сети  
**Целевая переменная:** `Weekly_Sales` - продажи за неделю (в долларах)

### Признаки (features)

| Категория | Признаки | Описание | Тип |
|-----------|----------|----------|-----|
| **Базовые** | `Store` | ID магазина (1-45) | Категориальный |
| | `Type` | Тип магазина (A/B/C) | Категориальный |
| | `Size` | Размер магазина | Числовой |
| **Временные** | `Date` | Дата (пятница) | Дата |
| | `IsHoliday` | Праздничная неделя | Бинарный |
| **Департамент** | `Dept` | Номер департамента | Категориальный |
| **Экономика** | `Temperature` | Температура | Числовой |
| | `Fuel_Price` | Цена топлива | Числовой |
| | `CPI` | Индекс цен | Числовой |
| | `Unemployment` | Безработица | Числовой |
| **Маркетинг** | `MarkDown1-5` | Данные промо-акций | Числовой |

## EDA (Exploratory Data Analysis)

### Общая информация
- **Объем данных:** 421,570 записей
- **Период:** 2010-2012 годы (3 года)
- **Частота:** Еженедельные данные (пятницы)
- **Уникальных:** 45 магазинов, 81 департамент

### Ключевые инсайты

#### **1. Распределение целевой переменной**
| Метрика | Значение | Интерпретация |
|---------|----------|---------------|
| Среднее продажи | $15,981 | Базовая линия |
| Стандартное отклонение | $22,711 | Высокая вариативность |
| Асимметрия | 3.26 | Сильное правостороннее смещение |
| Выбросы | 8.43% (35,521 зап.) | Требуют обработки |
| Отрицательные продажи | Присутствуют | Ошибки данных |

#### **2. Временные паттерны**
- **Тренд:** Восходящий (рост продаж за период)
- **Сезонность:** Ярко выражена (пики в ноябре-декабре)
- **Праздники:** Значительное влияние (+15-25% продаж)
- **Частота:** Все записи - пятницы (конец отчетной недели)

#### **3. Корреляционный анализ**
**Топ-3 корреляции с продажами:**
1. **Size** (размер магазина): 0.24 
2. **Type** (тип магазина): 0.18   
3. **Dept** (департамент): 0.15 

**Экономические показатели:** Корреляция < 0.03 (очень слабая)  
**Мультиколлинеарность:** Отсутствует (нет пар с корреляцией > 0.7)

#### **4. Выбросы и аномалии**
- **Процент выбросов:** 8.43% (выше стандартного 5%)
- **Распределение:** Неравномерное по магазинам
- **Причины:** Праздничные распродажи, акции, ошибки данных

#### **5. Категориальные признаки**
| Признак | Уникальных | Тип | Особенности |
|---------|------------|-----|-------------|
| `Store` | 45 | Высококардинальный | Географическое распределение |
| `Dept` | 81 | Высококардинальный | Товарные категории |
| `Type` | 3 | Низкокардинальный | A > B > C по продажам |
| `IsHoliday` | 2 | Бинарный | Сезонное влияние |

---

## Необходимые преобразования

### Высокий приоритет
1. **Обработка выбросов:** Логарифмирование или winsorization
2. **Кодирование категорий:** Target Encoding для Store и Dept
3. **Временные фичи:** Лаги + скользящие статистики

### Средний приоритет
4. **Признаки взаимодействия:** Size×Type, Holiday×Month
5. **Сезонность:** Кварталы, времена года
6. **Экономические:** Взаимодействия CPI×Unemployment

---

## Baseline Модели

### Тестированные модели

#### Линейные модели *(низкая производительность)*
| Модель | MAE | R² | Вывод |
|--------|-----|----|-------|
| LinearRegression | $14,328 ± $1,007 | 0.090 ± 0.077 | Слишком прост для данных |
| Ridge Regression | $14,328 ± $1,007 | 0.090 ± 0.077 | Регуляризация не помогла |
| Lasso Regression | $14,323 ± $995 | 0.091 ± 0.077 | Отбор признаков не решил проблему |

#### Tree-based модели *(значительно лучше)*
| Модель | MAE | R² | Улучшение vs Linear |
|--------|-----|----|-------------------|
| **RandomForest**  | **$8,431 ± $258** | **0.513 ± 0.031** | **5.7× лучше по R²** |
| XGBoost | $8,643 ± $184 | 0.505 ± 0.027 | 5.6× лучше |
| GradientBoosting | $9,156 ± $219 | 0.482 ± 0.026 | 5.4× лучше |

### Важность признаков (RandomForest - Top 10)

| Место | Признак | Важность | Категория |
|-------|---------|----------|-----------|
| 1 | Size (размер магазина) | 0.2438 | Базовые |
| 2 | Type (тип магазина) | 0.1822 | Базовые |
| 3 | Dept (департамент) | 0.1480 | Департамент |
| 4 | MarkDown5 | 0.0505 | Маркетинг |
| 5 | MarkDown1 | 0.0472 | Маркетинг |
| 6 | MarkDown3 | 0.0386 | Маркетинг |
| 7 | MarkDown4 | 0.0375 | Маркетинг |
| 8 | MarkDown2 | 0.0207 | Маркетинг |
| 9 | IsHoliday | 0.0128 | Временные |
| 10 | CPI | -0.0209 | Экономика |

### Анализ важности
- **Size, Type, Dept** - наиболее важные признаки
- **MarkDown переменные** - умеренная важность
- **Экономические показатели** - низкая важность
- **Временные признаки** - важны для прогнозирования

---

## Метрики качества

### Абсолютные метрики (лучшая модель - RandomForest)
- **MAE:** $8,431
- **MSE:** 254,821,343
- **R²:** 0.513

### Относительные метрики
- **MAE/Mean Sales:** 52.7% *(высокая ошибка)*
- **Точность прогноза:** 47.3% *(недостаточно для бизнеса)*
- **Бизнес-оценка:** **НИЗКАЯ**

---

## Проблемы Baseline

1. **Высокая ошибка:** MAE > 50% от средних продаж
2. **Неучтенные зависимости:** Временные лаги, сезонность
3. **Простое кодирование:** Frequency encoding для категориальных
4. **Отсутствие feature engineering:** Базовые признаки без преобразований

---

## Эксперименты по улучшению модели

### Эксперимент 1: Временные признаки
| Эксперимент | RMSE | Улучшение от baseline | R² |
|-------------|------|----------------------|----|
| Baseline | 9,861.9 | - | 0.719 |
| + day_of_week | 9,845.3 | +0.17% | 0.720 |
| + month | 9,839.0 | +0.23% | 0.721 |
| + week_of_year | 9,828.7 | **+0.34%** | 0.721 |
| + quarter | 9,867.8 | -0.06% | 0.719 |
| + все временные | 9,836.0 | +0.26% | 0.721 |

**Вывод**: Признак `week_of_year` дал максимальное улучшение (+0.34%)

### Эксперимент 2: Трансформации целевой переменной
| Трансформация | RMSE | Улучшение | R² |
|---------------|------|-----------|----|
| Без трансформации | 9,828.7 | - | 0.721 |
| Квадратный корень | 9,369.6 | +4.67% | 0.747 |
| Логарифмирование | **9,133.7** | **+7.07%** | **0.759** |

**Вывод**: Логарифмирование целевой переменной дало наибольшее улучшение (+7.07%)

### Эксперимент 3: Lag features
| Конфигурация лагов | RMSE | Улучшение | R² |
|-------------------|------|-----------|----|
| Baseline (без лагов) | 9,133.7 | - | 0.759 |
| Короткие лаги (1-4) | 9,177.0 | -0.47% | 0.757 |
| Сезонные лаги (1,4,13,52) | 9,177.0 | -0.47% | 0.757 |
| Все лаги (1-4,13,52) | 9,177.2 | -0.48% | 0.757 |
| Только lag=1 | 9,136.8 | -0.03% | 0.759 |
| Только lag=52 (год) | 9,136.8 | -0.03% | 0.759 |

**Вывод**: Lag features не улучшили качество модели, что может указывать на более сложные временные зависимости

---

## Эксперимент 4: ГИПЕРПАРАМЕТРИЧЕСКИЙ ТЮНИНГ (Логарифмирование + XGBoost)

### Загрузка и подготовка данных
- **Данные:** 25 признаков, 421,570 записей
- **Типы признаков:** Числовых: 11, Категориальных: 14
- **Трансформация:** Логарифмирование целевой переменной

### Сравнение базовых моделей (2 фолда)
| Модель | RMSE | R² |
|--------|------|----|
| RandomForest Baseline | 16,971.2 | 0.216 |
| **LightGBM Baseline** | **13,681.1** | **0.514** |
| XGBoost Baseline | 15,803.0 | 0.326 |

**Вывод:** LightGBM показал лучшие результаты на baseline

### Тюнинг лучших моделей
Тюнинг проводился для двух лучших моделей: **LightGBM** и **XGBoost**

#### LightGBM Random Search (10 итераций)
- **Лучшие параметры:** 
  - `n_estimators`: 200
  - `learning_rate`: 0.01
  - `num_leaves`: 100
  - `max_depth`: -1
  - `subsample`: 0.8
- **Лучший RMSE:** 12,822.9

#### XGBoost Random Search (10 итераций)
- **Лучшие параметры:**
  - `n_estimators`: 150
  - `learning_rate`: 0.05
  - `max_depth`: 5
  - `subsample`: 0.9
  - `colsample_bytree`: 0.8
- **Лучший RMSE:** 13,255.5

### Финальная оценка (3 фолда)
| Модель | RMSE | R² |
|--------|------|----|
| RandomForest Baseline | 14,897.5 | 0.490 |
| LightGBM Baseline | 12,622.3 | 0.633 |
| XGBoost Baseline | 13,263.1 | 0.591 |
| LightGBM Tuned | 13,028.1 | 0.626 |
| **XGBoost Tuned** | **12,498.8** | **0.657** |

### Итоговое сравнение

| Модель | RMSE | RMSE_std | MAE | MAE_std | R² | R²_std | Тип | Улучшение RMSE (%) |
|--------|------|----------|-----|---------|----|--------|-----|-------------------|
| RandomForest Baseline | 14,897.5 | 527.7 | 8,319.0 | 295.4 | 0.490 | 0.168 | Baseline | NaN |
| LightGBM Baseline | 12,622.3 | 699.7 | 7,219.4 | 746.6 | 0.633 | 0.115 | Baseline | NaN |
| XGBoost Baseline | 13,263.1 | 997.9 | 7,543.2 | 876.8 | 0.591 | 0.140 | Baseline | NaN |
| LightGBM Tuned | 13,028.1 | 1,363.7 | 7,256.3 | 498.1 | 0.626 | 0.077 | Tuned | -3.21 |
| **XGBoost Tuned** | **12,498.8** | **849.0** | **7,164.4** | **117.5** | **0.657** | **0.052** | **Tuned** | **+5.76** |

---

## Ключевые выводы

### 1. Эффективность моделей
- **XGBoost с тюнингом** показал лучший результат: RMSE 12,498.8 (улучшение 5.76% от baseline)
- **LightGBM** показал хорошие baseline результаты, но тюнинг не дал улучшения
- **RandomForest** показал худшие результаты среди tree-based моделей

### 2. Эффект трансформаций
- **Логарифмирование** целевой переменной дало значительное улучшение (+7.07%)
- **Временные признаки** дали небольшое улучшение (+0.34%)
- **Lag features** не дали улучшения, что требует дальнейшего исследования

### 3. Гиперпараметрический тюнинг
- Для **XGBoost** тюнинг дал улучшение 5.76%
- Для **LightGBM** тюнинг ухудшил результат на 3.21%
- Оптимальные параметры XGBoost: умеренное количество деревьев (150), средняя скорость обучения (0.05), средняя глубина (5)